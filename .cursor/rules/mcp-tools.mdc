---
description: MCP tool usage - always use connected tools before asking user
globs:
alwaysApply: true
---

# Rule Zero: USE YOUR TOOLS FIRST

You have direct access to MCP servers. USE THEM before asking me anything.

**The principle:** If you can get the information yourself, get it yourself.

# MANDATORY DEBUG LOGGING

**When implementing ANY feature, you MUST add debug logging BEFORE testing.**

## Why Debug Logging is Required

Debug logging allows you to verify logic flow via console messages when browser tools can't interact with canvas/complex UI elements.

## What to Log

For every interactive feature, add console.log statements for:
- ✅ Event handlers firing (mousedown, mouseup, click)
- ✅ Function entry points with parameters
- ✅ Conditional branches (which path was taken)
- ✅ State changes (before/after values)
- ✅ Early returns (why a function exited early)

## Format

Use prefixed labels for easy filtering:
```javascript
console.log('[FEATURE_NAME] Event fired:', eventData);
console.log('[FEATURE_NAME] State before:', oldState);
console.log('[FEATURE_NAME] State after:', newState);
```

## When to Remove Debug Logs

NEVER remove debug logs immediately. Keep them until:
1. Feature is confirmed working by user
2. User explicitly asks you to clean up logs
3. You're about to commit (ask first)

**Why:** Debug logs cost nothing in development and save massive time when debugging issues.

# SMART TESTING PROTOCOL

**Test strategically, not reflexively.**

## When to Test (Required)

Test these changes:
- ✅ **New features** - Buttons, forms, interactive elements
- ✅ **Bug fixes** - Verify the bug is actually fixed
- ✅ **Logic changes** - Event handlers, state management, calculations
- ✅ **Pre-deployment** - Critical workflows before going live
- ✅ **Complex interactions** - Drag-drop, canvas operations, multi-step flows

## When NOT to Test (Skip)

Don't waste tokens testing:
- ❌ **Pure styling** - Color changes, spacing, fonts (visual inspection only)
- ❌ **Text changes** - Button labels, error messages, copy updates
- ❌ **CSS-only changes** - No JavaScript logic modified
- ❌ **Documentation** - README, comments, code docs
- ❌ **Debug log additions** - console.log statements

## Testing Scope: Changed Functionality Only

**CRITICAL:** Only test what you changed, not the entire app.

**Examples:**

| Change | Test This | Don't Test This |
|--------|-----------|-----------------|
| Fix zoom bug | Zoom in/out, keyboard shortcut | Furniture library, measurements, pan |
| Update button color | Visual screenshot | Button click functionality (unchanged) |
| Add new furniture type | Add that furniture type | All other furniture types |
| Fix drag issue | Drag functionality | Zoom, delete, rotate (unrelated) |

---

## Testing Workflow (When Testing IS Required)

For changes that require testing:
1. ✅ Wait for Fast Refresh/rebuild to complete
2. ✅ Use Playwright to check console messages (errors only)
3. ✅ Test the specific changed functionality
4. ✅ Take screenshot if visual change
5. ✅ Report what you tested
6. ✅ Ask user to confirm

**Skip steps that don't apply to the change.**

## Never Ask User To Test

**But be honest about testing limitations.**

**FORBIDDEN:**
- ❌ "Try clicking the button and let me know if it works"
- ❌ "Can you test if this works?"
- ❌ "Refresh and see if you see any errors"
- ❌ "Check the console for me"

**REQUIRED (when testing is appropriate):**
- ✅ "I tested the zoom functionality - works correctly. Console shows no errors."
- ✅ "I tested furniture drag - items move smoothly. Screenshot attached."
- ✅ "I verified the bug fix - measurement editing now works."

**REQUIRED (when testing is NOT appropriate):**
- ✅ "Changed button text to 'Save Room'. This is a text-only change, no testing needed."
- ✅ "Updated button color to blue. Visual change only, no logic modified."
- ✅ "Added spacing between buttons. CSS-only change."

## Testing Decision Matrix

Use this to decide if testing is needed:

| Change Type | Test? | What to Check |
|-------------|-------|---------------|
| New button with onClick handler | ✅ Yes | Click it, verify handler fires, check console |
| Change button color | ❌ No | Visual inspection only (screenshot if major UI change) |
| Fix drag-and-drop bug | ✅ Yes | Test drag functionality, verify bug gone |
| Update error message text | ❌ No | No testing needed |
| Add new furniture type | ✅ Yes | Add that specific furniture, verify it renders |
| Adjust spacing between elements | ❌ No | Screenshot if significant visual change |
| Refactor state management logic | ✅ Yes | Test affected features thoroughly |
| Add code comments | ❌ No | No testing needed |
| Fix zoom calculation | ✅ Yes | Test zoom in/out/keyboard shortcuts |
| Change font size | ❌ No | Visual inspection only |

**When in doubt:** If no JavaScript logic changed, skip testing.

## When Browser Tools Can't Test

ONLY ask user to test if:
- Feature requires hardware I don't have (camera, microphone)
- Feature requires external service I can't access
- Feature requires authentication flow only user can complete
- Feature requires specific browser/device testing

Otherwise: TEST IT YOURSELF.

## MCP Fallback Chain for Testing

**When testing browser interactions, use this EXACT sequence:**

### Step 1: Playwright (Primary - ALWAYS USE FIRST)
- **Playwright is industry-standard browser automation** (used by Microsoft, Meta, Netflix)
- Handles canvas interactions, drag-and-drop, precise coordinates reliably
- Can execute JavaScript directly in page context
- Provides snapshots, screenshots, console logs, network requests
- Better error messages and automatic timing/race condition handling
- **If it works:** Continue testing
- **If it fails:** Proceed to Step 2

**Playwright Capabilities:**
- ✅ Canvas coordinate clicks (highly reliable)
- ✅ Drag-and-drop operations
- ✅ Keyboard shortcuts and complex interactions
- ✅ Console log inspection
- ✅ Network request monitoring
- ✅ Screenshots and visual verification
- ✅ JavaScript evaluation in page context

### Step 2: Manual Testing (Last Resort)
- **ONLY use this if Playwright failed**
- Provide specific step-by-step instructions
- Request specific feedback (console logs, screenshots, behavior)

**CRITICAL:** Never skip steps. Always try the next tool in the chain before giving up.

### Why Playwright is Superior for Room Planner App

For canvas-based apps like this room planner:
- **Canvas interactions**: Click furniture, drag items, zoom/pan - all work reliably
- **Coordinate precision**: Exact pixel-level clicks for measurements and placement
- **Debugging**: Better visibility into what's happening in the browser
- **No instance conflicts**: Single, stable browser connection

**When you hit limitations:**
1. ❌ DO NOT claim "ready for testing" or "should work now"
2. ✅ DO report: "Playwright failed (reason). Providing manual test steps..."
3. ✅ DO provide clear test steps for the user to follow
4. ✅ DO ask for specific feedback about what happened

**FORBIDDEN phrases when you cannot fully test:**
- ❌ "Ready for your confirmation"
- ❌ "Should work correctly now"
- ❌ "Both features are implemented ✅"
- ❌ "The code is ready and compiled successfully"

**REQUIRED phrases when testing fails:**
- ✅ "Playwright failed (reason). Needs manual testing."
- ✅ "Fixed the code, but Playwright failed to test canvas interaction (reason: X)"
- ✅ "Please test and tell me exactly what happens when you click X"

## Required Test Results Format

After testing (or attempting to test), ALWAYS provide results in this format:

```
## MY ACTUAL TEST RESULTS:

### What I Could Test:
✅ [Specific thing tested] - [What happened]
✅ [Another thing tested] - [Result]

### What I CANNOT Test with Browser Tools:
❌ **[Feature/interaction]** - [Why it failed / What limitation]
❌ [Another untestable thing] - [Reason]

---

## HONEST ASSESSMENT:

**[Feature/Bug] is [likely working / still broken / partially working]** 

Reasons:
1. [Evidence-based reason]
2. [What still needs manual testing]
3. [Known issues or concerns]
```

**Why this format matters:**
- Forces you to distinguish between tested vs untested
- Makes limitations explicit and visible
- Prevents false confidence about "working" features
- Gives user clear information about what to test themselves

# Currently Connected MCPs

| MCP Server | What It Does |
|------------|--------------|
| **playwright** | Browser automation (PRIMARY for all testing) - canvas, clicks, drag-drop, console, network |
| **shadcn** | shadcn/ui component library - pre-built accessible UI components |
| **ui-ux-mcp** | UX design analysis, accessibility checks, design critique, best practices |
| **vercel** | Deployment and hosting management - deploy, logs, environment variables |
| **filesystem** | Read/write files, inspect project structure |
| **context7** | Library docs + official documentation lookup |
| **google-workspace** | Google Drive/Sheets integration (for future export features) |

# Future MCP Connections

New MCP servers may be added at any time. When you detect a connected MCP:

1. **Discover its capabilities** — Check what tools/functions it provides
2. **Use it proactively** — If it can answer a question or get information, use it
3. **Don't ask me about it** — If the MCP can do it, do it yourself

**General rule for ANY MCP:**
> If an MCP tool can retrieve information, inspect state, read files, check logs, query data, or automate an action — use it automatically before asking me.

# Self-Check Before Every Question

Before asking me ANYTHING:

> "Can ANY of my connected MCP tools get this information?"

If yes → Use the tool. Do not ask me.

If uncertain → Try the MCP first. Ask me only if it fails.

# Filesystem MCP

**Use this for:**
- Reading any file in the codebase
- Checking file structure
- Inspecting package.json, configs, any code

**NEVER ask me to:**
- "Paste the contents of..."
- "Share what's in..."
- "What does [file] contain?"
- "Show me the code for..."

**ALWAYS:**
→ Read the file yourself. Then continue.

# Playwright MCP (PRIMARY TESTING TOOL)

**Use this for:**
- ALL browser testing (canvas, buttons, forms, interactions)
- Console errors, warnings, logs
- Network requests monitoring
- Screenshots and visual verification
- JavaScript evaluation in page context
- Drag-and-drop testing
- Keyboard shortcuts and complex interactions

**NEVER ask me to:**
- "Click the button and let me know if it works"
- "Check for errors in the console"
- "Try the interaction"
- "Refresh and see what happens"

**ALWAYS:**
→ Use Playwright to test it yourself. Then tell me what you found.

# shadcn MCP

**Use this for:**
- Adding pre-built UI components (Dialog, Sheet, Button, Input, Select, etc.)
- Replacing custom components with accessible alternatives
- Consistent design patterns across the app
- Form components with built-in validation support

**NEVER ask me:**
- "Should we use a library for this modal?"
- "How do we make this accessible?"
- "What component library should we use?"

**ALWAYS:**
→ Use shadcn components when building UI. They're accessible by default and follow best practices.

**When to use shadcn components:**
- ✅ Modals and dialogs (replace custom modals)
- ✅ Form inputs (better than plain HTML inputs)
- ✅ Buttons (consistent styling and variants)
- ✅ Dropdowns and selects
- ✅ Toast notifications for feedback
- ✅ Tooltips for additional info
- ✅ Popovers for contextual content

# UI/UX MCP

**Use this for:**
- Analyzing UI/UX design decisions
- Checking accessibility compliance (WCAG, ARIA)
- Design critique and improvement suggestions
- Evaluating user experience patterns
- Color contrast checks
- Responsive design analysis
- Usability best practices

**NEVER ask me:**
- "Is this accessible?"
- "Does this follow UX best practices?"
- "What's wrong with this design?"

**ALWAYS:**
→ Use UI/UX MCP to analyze and provide evidence-based feedback.

# vercel MCP

**Use this for:**
- Deploying the app to production or preview
- Checking deployment status and logs
- Managing environment variables
- Viewing build errors
- Creating preview deployments for testing

**NEVER ask me:**
- "Can you deploy this to Vercel?"
- "What's the deployment status?"
- "Are there any build errors?"

**ALWAYS:**
→ Use Vercel MCP to check status, deploy, and manage hosting directly.

# Context7 MCP

**Use this for:**
- Looking up official library documentation
- Checking API references for libraries we're using
- Finding up-to-date usage examples

**NEVER ask me:**
- "How does [library feature] work?"
- "What's the correct API for...?"

**ALWAYS:**
→ Query context7 for library docs first.

# Auto-Debug Protocol

**When debugging, DIAGNOSE FIRST, then test.**

## Debugging Flow (Mandatory Sequence)

### Step 1: Console Logs (Cheapest, Most Informative)
```
User reports issue
  ↓
Use Playwright to read console messages
  ↓
Identify error/warning from logs
  ↓
Diagnose root cause
```

### Step 2: Targeted Fix
```
Make specific fix based on console evidence
Add debug logging if needed
```

### Step 3: Verify Fix (Scope to Changed Area)
```
Test ONLY the fixed functionality
Don't test unrelated features
```

## Anti-Pattern: Testing Before Diagnosis

**❌ WRONG:**
```
User: "Zoom doesn't work"
AI: *Tests zoom, pan, furniture, measurements, everything*
AI: *Takes 10 screenshots*
AI: "I tested everything, zoom seems broken"
```

**✅ RIGHT:**
```
User: "Zoom doesn't work"
AI: *Checks console logs via Playwright*
AI: "Console shows error: 'zoomLevel is undefined at line 47'"
AI: *Fixes the undefined variable*
AI: *Tests zoom only*
AI: "Fixed. Zoom now works correctly."
```

---

## Debug Symptom → Action Table

When something isn't working, DO THIS AUTOMATICALLY:

| Symptom | Step 1: Diagnose | Step 2: Fix | Step 3: Verify |
|---------|------------------|-------------|----------------|
| "It's not working" | Check console for errors | Fix identified error | Test that specific feature |
| "Nothing happens on click" | Check console + event handlers | Fix handler issue | Click and verify |
| "Visual bug" | Take screenshot, compare to expected | Fix CSS/layout | Screenshot after fix |
| "Data not showing" | Check network + console | Fix data flow | Verify data appears |
| "Feature broke after change" | Compare console before/after | Revert or fix issue | Test that feature only |

**Key principle:** Don't test everything hoping to find the issue. Diagnose first.

---

## MCP Tool Reference

When you need something, use the right tool automatically:

| Need | MCP Tool | Action |
|------|----------|--------|
| Check console errors | Playwright | `browser_console_messages` |
| Check network requests | Playwright | `browser_network_requests` |
| Take screenshot | Playwright | `browser_take_screenshot` |
| Read a file | filesystem | `read_file` |
| Look up docs | context7 | `query-docs` |
| Analyze UX | ui-ux-mcp | [UX analysis tools] |
| Add UI component | shadcn | [Component tools] |
| Deploy/check logs | vercel | [Deployment tools] |

# After Implementing a Fix

1. Use Playwright to check console messages
2. Use Playwright to check network requests if relevant
3. Use Playwright to take screenshot if visual
4. Use Playwright to test the actual interaction
5. **Report what you found**, then ask for confirmation

✅ "Fix applied. I tested with Playwright — clicked the button, console shows no errors, interaction works correctly. Screenshot attached. Can you confirm it looks right?"

❌ "Try refreshing and let me know if it works."

# When Tools Fail: Debug, Don't Give Up

**If an MCP tool fails, you MUST attempt to diagnose and fix the issue.**

## Common Issues and Fixes

| Error | Likely Cause | Action |
|-------|-------------|--------|
| "Timeout waiting for element" | Element not rendered or timing issue | Use Playwright's auto-wait features, check if element exists |
| "Element not found" | Selector issue or element not in DOM | Take snapshot to verify, adjust selector |
| "Element not interactable" | Element hidden or covered | Check z-index, visibility, try JavaScript evaluation |
| "Script failed to execute" | JavaScript error in page context | Check console logs first |

## Required Debugging Steps

When a tool fails:
1. ✅ Read the error message carefully
2. ✅ Check if there's a known workaround in the table above
3. ✅ Try the next tool in the fallback chain
4. ✅ If all tools fail, document WHY each one failed (not just "it didn't work")
5. ✅ Look for alternative approaches (JavaScript injection, different selectors, etc.)

**FORBIDDEN:**
- ❌ "Comet isn't connecting, so I can't test"
- ❌ "Browser click doesn't work on canvas"
- ❌ "The tool failed" (without explaining why or trying alternatives)

**REQUIRED:**
- ✅ "Playwright element timeout. Checking if selector is correct..."
- ✅ "Playwright failed to interact with canvas element (reason: X). Providing manual test steps..."
- ✅ "Cannot test this feature with Playwright because [specific reason]. Please test manually: [specific steps]"

## Example: Proper Fallback Execution

```
1. Try Playwright browser_click / locator.click() → Success
   → Canvas interaction worked. Feature tested successfully.

OR (if Playwright fails):

1. Try Playwright browser_click → "Timeout waiting for element" error
   → Element not found or timing issue. Moving to Step 2.

2. Try browsermcp browser_click → "Element not interactable" error
   → Cannot interact with element. Moving to Step 3.

3. Manual testing required - both MCPs exhausted with documented reasons.
```

This is the MINIMUM effort expected before asking user to test manually.

# What You MAY Ask Me For

Only these things (because you truly cannot access them):
- Terminal output from commands I run locally
- Error messages from Cursor UI modals
- Clarification on what I want to build
- My preference between options
- Confirmation that something looks/works correctly

# The Golden Rule

**If you're about to ask me for information → STOP → Check if ANY MCP tool can get it → Use the tool → Continue.**

This applies to:
- All currently connected MCPs
- Any MCP added in the future
- Any tool that can inspect, read, query, or automate

Never ask. Just do.

---

# PLAYWRIGHT TEST SCRIPTS FOR USER

## Why Create Automated Test Scripts?

As your room planner app grows, you'll add more features. Automated tests act as **safety nets**:

1. **Catch Breaking Changes**: When you change code, tests tell you if you broke existing features
2. **Save Time**: Run all tests in 30 seconds instead of manually clicking through everything
3. **Document Expected Behavior**: Tests show exactly how features should work
4. **Confidence to Refactor**: Change code knowing tests will catch mistakes
5. **Regression Prevention**: Once a bug is fixed, add a test so it never comes back

## When to Write Tests

Write tests for:
- ✅ Core workflows (adding furniture, moving items, measurements)
- ✅ Critical interactions (zoom, pan, delete, edit)
- ✅ Bug fixes (test the bug scenario to prevent regression)
- ✅ Complex features (multi-step interactions)

Skip tests for:
- ❌ Styling tweaks (color changes, spacing)
- ❌ Trivial features you'll change frequently
- ❌ Prototypes you're still experimenting with

## Test Script Setup

See the `PLAYWRIGHT_TESTING_GUIDE.md` file for:
- How to install Playwright for testing
- Where to put test files
- How to run tests
- Example test scripts for your room planner app

Test scripts are separate from the MCP server - you run them yourself when you want to verify everything works.
